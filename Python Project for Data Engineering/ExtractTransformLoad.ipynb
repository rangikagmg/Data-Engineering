{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "<center>\n    <img src=\"https://gitlab.com/ibm/skills-network/courses/placeholder101/-/raw/master/labs/module%201/images/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "# **Extract Transform Load (ETL) Lab**\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Estimated time needed: **30** minutes\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Read CSV and JSON file types.\n*   Extract data from the above file types.\n*   Transform data.\n*   Save the transformed data in a ready-to-load format which data engineers can use to load into an RDBMS.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Import the required modules and functions\n"}, {"metadata": {}, "cell_type": "code", "source": "import glob                         # this module helps in selecting files \nimport pandas as pd                 # this module helps in processing CSV files\nimport xml.etree.ElementTree as ET  # this module helps in processing XML files.\nfrom datetime import datetime", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Download Files\n"}, {"metadata": {}, "cell_type": "code", "source": "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "--2021-12-16 21:07:14--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\nResolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\nConnecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2707 (2.6K) [application/zip]\nSaving to: \u2018source.zip\u2019\n\nsource.zip          100%[===================>]   2.64K  --.-KB/s    in 0s      \n\n2021-12-16 21:07:14 (53.8 MB/s) - \u2018source.zip\u2019 saved [2707/2707]\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Unzip Files\n"}, {"metadata": {}, "cell_type": "code", "source": "!unzip source.zip", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Archive:  source.zip\r\n  inflating: source3.json            \r\n  inflating: source1.csv             \r\n  inflating: source2.csv             \r\n  inflating: source3.csv             \r\n  inflating: source1.json            \r\n  inflating: source2.json            \r\n  inflating: source1.xml             \r\n  inflating: source2.xml             \r\n  inflating: source3.xml             \r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Set Paths\n"}, {"metadata": {}, "cell_type": "code", "source": "tmpfile    = \"temp.tmp\"               # file used to store all extracted data\nlogfile    = \"logfile.txt\"            # all event logs will be stored in this file\ntargetfile = \"transformed_data.csv\"   # file where transformed data is stored", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Extract\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### CSV Extract Function\n"}, {"metadata": {}, "cell_type": "code", "source": "def extract_from_csv(file_to_process):\n    dataframe = pd.read_csv(file_to_process)\n    return dataframe", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### JSON Extract Function\n"}, {"metadata": {}, "cell_type": "code", "source": "def extract_from_json(file_to_process):\n    dataframe = pd.read_json(file_to_process,lines=True)\n    return dataframe", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### XML Extract Function\n"}, {"metadata": {}, "cell_type": "code", "source": "def extract_from_xml(file_to_process):\n    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n    tree = ET.parse(file_to_process)\n    root = tree.getroot()\n    for person in root:\n        name = person.find(\"name\").text\n        height = float(person.find(\"height\").text)\n        weight = float(person.find(\"weight\").text)\n        dataframe = dataframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n    return dataframe", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Extract Function\n"}, {"metadata": {}, "cell_type": "code", "source": "def extract():\n    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n    \n    #process all csv files\n    for csvfile in glob.glob(\"*.csv\"):\n        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n        \n    #process all json files\n    for jsonfile in glob.glob(\"*.json\"):\n        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n    \n    #process all xml files\n    for xmlfile in glob.glob(\"*.xml\"):\n        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n        \n    return extracted_data", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Transform\n"}, {"metadata": {}, "cell_type": "markdown", "source": "The transform function does the following tasks.\n\n1.  Convert height which is in inches to millimeter\n2.  Convert weight which is in pounds to kilograms\n"}, {"metadata": {}, "cell_type": "code", "source": "def transform(data):\n        #Convert height which is in inches to millimeter\n        #Convert the datatype of the column into float\n        #data.height = data.height.astype(float)\n        #Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)\n        data['height'] = round(data.height * 0.0254,2)\n        \n        #Convert weight which is in pounds to kilograms\n        #Convert the datatype of the column into float\n        #data.weight = data.weight.astype(float)\n        #Convert pounds to kilograms and round off to two decimals(one pound is 0.45359237 kilograms)\n        data['weight'] = round(data.weight * 0.45359237,2)\n        return data", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Loading\n"}, {"metadata": {}, "cell_type": "code", "source": "def load(targetfile,data_to_load):\n    data_to_load.to_csv(targetfile)  ", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Logging\n"}, {"metadata": {}, "cell_type": "code", "source": "def log(message):\n    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n    now = datetime.now() # get current timestamp\n    timestamp = now.strftime(timestamp_format)\n    with open(\"logfile.txt\",\"a\") as f:\n        f.write(timestamp + ',' + message + '\\n')", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Running ETL Process\n"}, {"metadata": {}, "cell_type": "code", "source": "log(\"ETL Job Started\")", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "log(\"Extract phase Started\")\nextracted_data = extract()\nlog(\"Extract phase Ended\")\nextracted_data", "execution_count": 15, "outputs": [{"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "      name  height  weight Unnamed: 0  Rates Name  Market Cap (GBP$ Billion)  \\\n0     alex   65.78  112.99        NaN    NaN  NaN                        NaN   \n1     ajay   71.52  136.49        NaN    NaN  NaN                        NaN   \n2    alice   69.40  153.03        NaN    NaN  NaN                        NaN   \n3     ravi   68.22  142.34        NaN    NaN  NaN                        NaN   \n4      joe   67.79  144.30        NaN    NaN  NaN                        NaN   \n..     ...     ...     ...        ...    ...  ...                        ...   \n139   ivan   67.62  114.14        NaN    NaN  NaN                        NaN   \n140  simon   67.90  112.37        NaN    NaN  NaN                        NaN   \n141  jacob   66.78  120.67        NaN    NaN  NaN                        NaN   \n142  cindy   66.49  127.45        NaN    NaN  NaN                        NaN   \n143   ivan   67.62  114.14        NaN    NaN  NaN                        NaN   \n\n    Market Cap (US$ Billion)  \n0                        NaN  \n1                        NaN  \n2                        NaN  \n3                        NaN  \n4                        NaN  \n..                       ...  \n139                      NaN  \n140                      NaN  \n141                      NaN  \n142                      NaN  \n143                      NaN  \n\n[144 rows x 8 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>Unnamed: 0</th>\n      <th>Rates</th>\n      <th>Name</th>\n      <th>Market Cap (GBP$ Billion)</th>\n      <th>Market Cap (US$ Billion)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>alex</td>\n      <td>65.78</td>\n      <td>112.99</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ajay</td>\n      <td>71.52</td>\n      <td>136.49</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>alice</td>\n      <td>69.40</td>\n      <td>153.03</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ravi</td>\n      <td>68.22</td>\n      <td>142.34</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>joe</td>\n      <td>67.79</td>\n      <td>144.30</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>ivan</td>\n      <td>67.62</td>\n      <td>114.14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>simon</td>\n      <td>67.90</td>\n      <td>112.37</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>jacob</td>\n      <td>66.78</td>\n      <td>120.67</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>cindy</td>\n      <td>66.49</td>\n      <td>127.45</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>ivan</td>\n      <td>67.62</td>\n      <td>114.14</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>144 rows \u00d7 8 columns</p>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "log(\"Transform phase Started\")\ntransformed_data = transform(extracted_data)\nlog(\"Transform phase Ended\")\ntransformed_data ", "execution_count": 16, "outputs": [{"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "      name  height  weight Unnamed: 0  Rates Name  Market Cap (GBP$ Billion)  \\\n0     alex    1.67   51.25        NaN    NaN  NaN                        NaN   \n1     ajay    1.82   61.91        NaN    NaN  NaN                        NaN   \n2    alice    1.76   69.41        NaN    NaN  NaN                        NaN   \n3     ravi    1.73   64.56        NaN    NaN  NaN                        NaN   \n4      joe    1.72   65.45        NaN    NaN  NaN                        NaN   \n..     ...     ...     ...        ...    ...  ...                        ...   \n139   ivan    1.72   51.77        NaN    NaN  NaN                        NaN   \n140  simon    1.72   50.97        NaN    NaN  NaN                        NaN   \n141  jacob    1.70   54.73        NaN    NaN  NaN                        NaN   \n142  cindy    1.69   57.81        NaN    NaN  NaN                        NaN   \n143   ivan    1.72   51.77        NaN    NaN  NaN                        NaN   \n\n    Market Cap (US$ Billion)  \n0                        NaN  \n1                        NaN  \n2                        NaN  \n3                        NaN  \n4                        NaN  \n..                       ...  \n139                      NaN  \n140                      NaN  \n141                      NaN  \n142                      NaN  \n143                      NaN  \n\n[144 rows x 8 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>Unnamed: 0</th>\n      <th>Rates</th>\n      <th>Name</th>\n      <th>Market Cap (GBP$ Billion)</th>\n      <th>Market Cap (US$ Billion)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>alex</td>\n      <td>1.67</td>\n      <td>51.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ajay</td>\n      <td>1.82</td>\n      <td>61.91</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>alice</td>\n      <td>1.76</td>\n      <td>69.41</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ravi</td>\n      <td>1.73</td>\n      <td>64.56</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>joe</td>\n      <td>1.72</td>\n      <td>65.45</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>ivan</td>\n      <td>1.72</td>\n      <td>51.77</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>simon</td>\n      <td>1.72</td>\n      <td>50.97</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>jacob</td>\n      <td>1.70</td>\n      <td>54.73</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>cindy</td>\n      <td>1.69</td>\n      <td>57.81</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>143</th>\n      <td>ivan</td>\n      <td>1.72</td>\n      <td>51.77</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>144 rows \u00d7 8 columns</p>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "log(\"Load phase Started\")\nload(targetfile,transformed_data)\nlog(\"Load phase Ended\")", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "log(\"ETL Job Ended\")", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Exercise\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Using the example above complete the exercise below.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Download Files\n"}, {"metadata": {}, "cell_type": "code", "source": "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "--2021-12-16 21:10:09--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\nResolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 198.23.119.245\nConnecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|198.23.119.245|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4249 (4.1K) [application/zip]\nSaving to: \u2018datasource.zip\u2019\n\ndatasource.zip      100%[===================>]   4.15K  --.-KB/s    in 0s      \n\n2021-12-16 21:10:09 (105 MB/s) - \u2018datasource.zip\u2019 saved [4249/4249]\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Unzip Files\n"}, {"metadata": {}, "cell_type": "code", "source": "!unzip datasource.zip -d dealership_data", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "Archive:  datasource.zip\r\n  inflating: dealership_data/used_car_prices1.csv  \r\n  inflating: dealership_data/used_car_prices2.csv  \r\n  inflating: dealership_data/used_car_prices3.csv  \r\n  inflating: dealership_data/used_car_prices1.json  \r\n  inflating: dealership_data/used_car_prices2.json  \r\n  inflating: dealership_data/used_car_prices3.json  \r\n  inflating: dealership_data/used_car_prices1.xml  \r\n  inflating: dealership_data/used_car_prices2.xml  \r\n  inflating: dealership_data/used_car_prices3.xml  \r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## About the Data\n"}, {"metadata": {}, "cell_type": "markdown", "source": "The file `dealership_data` contains CSV, JSON, and XML files for used car data which contain features named `car_model`, `year_of_manufacture`, `price`, and `fuel`.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Set Paths\n"}, {"metadata": {}, "cell_type": "code", "source": "tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\nlogfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\ntargetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Extract\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Question 1: CSV Extract Function\n"}, {"metadata": {}, "cell_type": "code", "source": "# Add the CSV extract function below\ndef extract_from_csv(file_to_process):\n    dataframe = pd.read_csv(file_to_process)\n    return dataframe", "execution_count": 45, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```\n    \ndef extract_from_csv(file_to_process):\n    dataframe = pd.read_csv(file_to_process)\n    return dataframe\n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Question 2: JSON Extract Function\n"}, {"metadata": {}, "cell_type": "code", "source": "# Add the JSON extract function below\ndef extract_from_json(file_to_process):\n    dataframe = pd.read_json(file_to_process, lines = True)\n    return dataframe", "execution_count": 46, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```\n    \ndef extract_from_json(file_to_process):\n    dataframe = pd.read_json(file_to_process,lines=True)\n    return dataframe\n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Question 3: XML Extract Function\n"}, {"metadata": {}, "cell_type": "code", "source": "# Add the XML extract function below, it is the same as the xml extract function above but the column names need to be renamed.\ndef extract_from_xml(file_to_process):\n    dataframe = pd.DataFrame(columns = ['car_model', 'year_of_manufacture', 'price' , 'fuel'])\n    tree = ET.parse(file_to_process)\n    root = tree.getroot()\n    for person in root:\n        car_model = person.find(\"car_model\").text\n        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n        price = float(person.find(\"price\").text)\n        fuel = person.find(\"fuel\").text\n        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\": year_of_manufacture, \"price\": price , \"fuel\": fuel}, ignore_index = True)\n    return dataframe", "execution_count": 53, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```\n    \ndef extract_from_xml(file_to_process):\n    dataframe = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel'])\n    tree = ET.parse(file_to_process)\n    root = tree.getroot()\n    for person in root:\n        car_model = person.find(\"car_model\").text\n        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n        price = float(person.find(\"price\").text)\n        fuel = person.find(\"fuel\").text\n        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True)\n    return dataframe\n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Question 4: Extract Function\n\nCall the specific extract functions you created above by replacing the `ADD_FUNCTION_CALL` with the proper function call.\n"}, {"metadata": {}, "cell_type": "code", "source": "def extract():\n    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n\n    #process all csv files\n    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n\n    #process all json files\n    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n\n    #process all xml files\n    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n\n    return extracted_data", "execution_count": 54, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```\n    \ndef extract():\n    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n    \n    #process all csv files\n    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n        \n    #process all json files\n    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n    \n    #process all xml files\n    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n        \n    return extracted_data\n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Transform\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Question 5: Transform\n\nRound the `price` columns to 2 decimal places\n"}, {"metadata": {}, "cell_type": "code", "source": "# Add the transform function below\ndef transform(data):\n    data['price'] = round(data.price, 2)\n    return data", "execution_count": 55, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```\n\ndef transform(data):\n        data['price'] = round(data.price, 2)\n        return data\n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Loading\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Question 6: Load\n"}, {"metadata": {}, "cell_type": "code", "source": "# Add the load function below\ndef load(targetfile, data_to_load):\n    data_to_load.to_csv(targetfile)\n    ", "execution_count": 56, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```\n\ndef load(targetfile,data_to_load):\n    data_to_load.to_csv(targetfile)  \n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Logging\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Question 7: Log\n\nMake sure to change the name of the logfile to the one specified in the set paths section. Change the timestamp order to Hour-Minute-Second-Monthname-Day-Year.\n"}, {"metadata": {}, "cell_type": "code", "source": "# Add the log function below\ndef log(message):\n    timestamp_format = '%H:%M:%S-%h-%d-%Y' #Hour-Minute-Second-MonthName-Day-Year\n    now = datetime.now() # get current timestamp\n    timestamp = now.strftime(timestamp_format)\n    with open(\"dealership_logfile.txt\",\"a\") as f:\n        f.write(timestamp + ',' + message + '\\n') ", "execution_count": 57, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```\n\ndef log(message):\n    timestamp_format = '%H:%M:%S-%h-%d-%Y' #Hour-Minute-Second-MonthName-Day-Year\n    now = datetime.now() # get current timestamp\n    timestamp = now.strftime(timestamp_format)\n    with open(\"dealership_logfile.txt\",\"a\") as f:\n        f.write(timestamp + ',' + message + '\\n') \n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Running ETL Process\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Question 8: ETL Process\n\nRun all functions to extract, transform, and load the data. Make sure to log all events using the `log` function. Place your code under each comment.\n"}, {"metadata": {}, "cell_type": "code", "source": "# Log that you have started the ETL process\nlog(\"ETL Job started\")\n\n# Log that you have started the Extract step\nlog(\"Extract Phase STarted\")\n\n# Call the Extract function\nextracted_data = extract()\n\n# Log that you have completed the Extract step\nlog(\"Extract Phase End\")\n\n# Log that you have started the Transform step\nlog(\"Tranform Phase Started\")\n\n# Call the Transform function\ntransformed_data = transform(extracted_data)\n# Log that you have completed the Transform step\n\nlog(\"Transform Phase Ended\")\n# Log that you have started the Load step\nlog(\"Load Phase Started\")\n# Call the Load function\nload(targetfile, transformed_data)\n# Log that you have completed the Load step\n\nlog(\"Load Phase Ended\")\n# Log that you have completed the ETL process\nlog(\"ETL Job Ended\")", "execution_count": 59, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<details><summary>Click here for the solution</summary>\n\n```\n\nlog(\"ETL Job Started\")\n\nlog(\"Extract phase Started\")\nextracted_data = extract()\nlog(\"Extract phase Ended\")\n\nlog(\"Transform phase Started\")\ntransformed_data = transform(extracted_data)\nlog(\"Transform phase Ended\")\n\nlog(\"Load phase Started\")\nload(targetfile,transformed_data)\nlog(\"Load phase Ended\")\n\nlog(\"ETL Job Ended\")\n```\n\n</details>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Authors\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Ramesh Sannareddy\n\nJoseph Santarcangelo\n\nAzim Hirjani\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Change Log\n"}, {"metadata": {}, "cell_type": "markdown", "source": "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n| ----------------- | ------- | ----------------- | ---------------------------------- |\n| 2020-11-25        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Copyright \u00a9 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0221ENSkillsNetwork23455645-2021-01-01&cm_mmc=Email_Newsletter-\\_-Developer_Ed%2BTech-\\_-WW_WW-\\_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork-23455645&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}